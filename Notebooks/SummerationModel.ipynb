{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWZdFlA93IqU"
   },
   "source": [
    "# Template Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.21.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: SentencePiece in /opt/conda/lib/python3.11/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install datasets\n",
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the input texts.\n",
    "    model_inputs = tokenizer(examples['article'], max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(text_target=examples['highlights'], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3004db84596a4a06882286daf324eac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "subsample_size = 500  # Num of samples\n",
    "\n",
    "subsampled_train_dataset = dataset['train'].shuffle(seed=42).select(range(subsample_size)).map(preprocess_function, batched=True)\n",
    "subsampled_val_dataset = dataset['validation'].shuffle(seed=42).select(range(1000)).map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../src/model/results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,    \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='../src/model/logs',            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=subsampled_train_dataset,         \n",
    "    eval_dataset=subsampled_val_dataset,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 38:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=4.586693684895834, metrics={'train_runtime': 2329.2452, 'train_samples_per_second': 0.644, 'train_steps_per_second': 0.161, 'total_flos': 203012702208000.0, 'train_loss': 4.586693684895834, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Aivia is a personal assistant designed to redefine the way individuals manage their daily tasks and interactions. Aivia is a companion designed to learn from and adapt to your personal preferences. Aivia is a companion designed to learn from and adapt to the user's mood and circumstances. Innovatech has unveiled its latest product: Aivia.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "def generate_summary(text, model, tokenizer):\n",
    "    # Prefix required by T5 to understand that it's a summarization task\n",
    "    preprocess_text = \"summarize: \" + text\n",
    "    inputs = tokenizer.encode(preprocess_text, return_tensors=\"pt\", max_length=512, truncation=True).to('cpu')\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "text = \"\"\"\n",
    "Title: Next-Gen Eco-Friendly Transportation: \"EcoMove\" Unveils Hydrogen-Powered Vehicles\n",
    "\n",
    "Date: April 15, 2024\n",
    "\n",
    "Location: Berlin, Germany\n",
    "\n",
    "In an ambitious move set to revolutionize the transportation industry, the innovative startup EcoMove unveiled its new line of hydrogen-powered vehicles at a grand event in Berlin today. Amidst growing concerns over climate change and the environmental impact of fossil fuels, EcoMove's launch represents a significant leap towards sustainable, eco-friendly transportation solutions.\n",
    "\n",
    "\"EcoMove is not just launching a new vehicle; we're introducing a new era of transportation that aligns with our vision for a cleaner, greener planet,\" stated EcoMove's CEO, Dr. Lena Hoffmann, during the product reveal. The company's flagship model, the H2Rover, combines cutting-edge technology with sleek design, offering both efficiency and performance without compromising on environmental values.\n",
    "\n",
    "The H2Rover stands out for its zero-emission technology. Unlike traditional electric vehicles that rely on lithium batteries, which pose recycling and mining concerns, the H2Rover utilizes hydrogen fuel cells. These cells generate electricity through a chemical reaction between hydrogen and oxygen, with water vapor as the only byproduct, thereby eliminating harmful emissions.\n",
    "\n",
    "The unveiling event showcased the H2Rover's innovative features, including its advanced fuel cell technology, regenerative braking system, and state-of-the-art safety protocols. With a range of over 600 kilometers on a single fueling and a refueling time of less than five minutes, the H2Rover addresses one of the most significant barriers to hydrogen vehicle adoption: convenience.\n",
    "\n",
    "EcoMove's approach extends beyond the vehicles themselves, as the company has announced partnerships with renewable energy providers to establish a network of green hydrogen fueling stations across Europe. \"Our goal is to make hydrogen fuel both accessible and sustainable, ensuring that every kilometer driven by an H2Rover contributes to our vision of a carbon-neutral future,\" explained Hoffmann.\n",
    "\n",
    "The response from the industry and environmental groups has been overwhelmingly positive, with many praising EcoMove's commitment to innovation and sustainability. \"EcoMove is setting a new standard for the automotive industry,\" said Kai Müller, Executive Director of GreenFuture, an environmental NGO. \"Their holistic approach to eco-friendly transportation, from vehicle design to fuel production and distribution, marks a significant step forward in our fight against climate change.\"\n",
    "\n",
    "As EcoMove prepares for the commercial release of the H2Rover, the company faces the challenge of scaling its technology and infrastructure to meet anticipated demand. However, with strong backing from investors and a clear commitment to sustainability, EcoMove is poised to lead the transition to eco-friendly transportation on a global scale.\n",
    "\n",
    "With the launch of the H2Rover, EcoMove not only promises a future where vehicles no longer contribute to pollution but also inspires other companies to pursue innovation in green technology. As the world looks for solutions to environmental challenges, EcoMove's pioneering work serves as a beacon of hope and progress.\n",
    "\n",
    "EcoMove has announced that the H2Rover will be available for pre-order starting June 2024, with the first deliveries expected by the end of the year. As the automotive world watches closely, EcoMove's journey may well redefine our relationship with vehicles and the environment for generations to come.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "summary = generate_summary(text, model, tokenizer)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"../src/model/t5_model\"\n",
    "tokenizer_save_path = \"../src/model/t5_tokenizer\"\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Creating Input for SHAP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
